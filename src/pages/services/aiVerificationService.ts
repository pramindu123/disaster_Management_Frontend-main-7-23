// AI Image Verification Service
// This module provides AI-powered image authenticity verification for disaster reports
// Using Google Gemini Flash API for real-time image analysis

export interface VerificationResult {
  isVerifying: boolean;
  isAuthentic: boolean | null;
  confidence: number;
  analysis: string;
  matchScore: number;
  flags: string[];
}

export interface AIVerificationOptions {
  strictMode?: boolean;
  minConfidenceThreshold?: number;
  checkMetadata?: boolean;
  detectDeepfakes?: boolean;
}

export interface GeminiResponse {
  candidates: Array<{
    content: {
      parts: Array<{
        text: string;
      }>;
    };
    finishReason: string;
    index: number;
    safetyRatings: Array<{
      category: string;
      probability: string;
    }>;
  }>;
}

// Real AI Service using Google Gemini Flash API
export class ImageVerificationService {
  private static instance: ImageVerificationService;
  private apiKey: string = 'AIzaSyCWr6cnOcZaaU-eTqw_nGz4G0wbHYGygig';
  private apiEndpoint: string = 'https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent';

  static getInstance(): ImageVerificationService {
    if (!ImageVerificationService.instance) {
      ImageVerificationService.instance = new ImageVerificationService();
    }
    return ImageVerificationService.instance;
  }

  /**
   * Verify if an image matches the provided description using Gemini Flash API
   * Real-time AI analysis for disaster report verification
   */
  async verifyImageAuthenticity(
    imageUrl: string, 
    description: string, 
    options: AIVerificationOptions = {}
  ): Promise<VerificationResult> {
    
    const {
      strictMode = false,
      minConfidenceThreshold = 0.7,
      checkMetadata = true,
      detectDeepfakes = true
    } = options;

    // Only use Gemini API, do not fallback to mock analysis
    // Convert image to base64 for Gemini API
    try {
      const imageBase64 = await this.convertImageToBase64(imageUrl);
      // Call Gemini Flash API for comprehensive analysis
      const geminiAnalysis = await this.analyzeWithGemini(imageBase64, description, options);
      return geminiAnalysis;
    } catch (error) {
      console.error('Gemini AI Verification failed:', error);
      throw error;
    }
  }

  /**
   * Convert image URL to base64 format required by Gemini API
   */
  private async convertImageToBase64(imageUrl: string): Promise<string> {
    try {
      const response = await fetch(imageUrl);
      const blob = await response.blob();
      
      return new Promise((resolve, reject) => {
        const reader = new FileReader();
        reader.onloadend = () => {
          const base64String = reader.result as string;
          // Remove data:image/jpeg;base64, prefix
          const base64Data = base64String.split(',')[1];
          resolve(base64Data);
        };
        reader.onerror = reject;
        reader.readAsDataURL(blob);
      });
    } catch (error) {
      throw new Error(`Failed to convert image to base64: ${error}`);
    }
  }

  /**
   * Analyze image and description using Google Gemini Flash API
   */
  private async analyzeWithGemini(
    imageBase64: string, 
    description: string, 
    options: AIVerificationOptions
  ): Promise<VerificationResult> {
    
    if (!this.apiKey) {
      throw new Error('Gemini API key not found. Please set REACT_APP_GEMINI_API_KEY in environment variables.');
    }

    const prompt = this.constructGeminiPrompt(description, options);
    
    const requestBody = {
      contents: [{
        parts: [
          {
            text: prompt
          },
          {
            inline_data: {
              mime_type: "image/jpeg",
              data: imageBase64
            }
          }
        ]
      }],
      generationConfig: {
        temperature: 0.1,
        topK: 32,
        topP: 1,
        maxOutputTokens: 1024,
      },
      safetySettings: [
        {
          category: "HARM_CATEGORY_HARASSMENT",
          threshold: "BLOCK_MEDIUM_AND_ABOVE"
        },
        {
          category: "HARM_CATEGORY_HATE_SPEECH",
          threshold: "BLOCK_MEDIUM_AND_ABOVE"
        },
        {
          category: "HARM_CATEGORY_SEXUALLY_EXPLICIT",
          threshold: "BLOCK_MEDIUM_AND_ABOVE"
        },
        {
          category: "HARM_CATEGORY_DANGEROUS_CONTENT",
          threshold: "BLOCK_MEDIUM_AND_ABOVE"
        }
      ]
    };

    try {
      const response = await fetch(`${this.apiEndpoint}?key=${this.apiKey}`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify(requestBody)
      });

      if (!response.ok) {
        throw new Error(`Gemini API error: ${response.status} ${response.statusText}`);
      }

      const geminiResponse: GeminiResponse = await response.json();
      
      if (!geminiResponse.candidates || geminiResponse.candidates.length === 0) {
        throw new Error('No response from Gemini API');
      }

      const analysisText = geminiResponse.candidates[0].content.parts[0].text;
      
      return this.parseGeminiResponse(analysisText, options);

    } catch (error) {
      throw new Error(`Gemini API request failed: ${error}`);
    }
  }

  /**
   * Construct a comprehensive prompt for Gemini analysis
   */
  private constructGeminiPrompt(description: string, options: AIVerificationOptions): string {
    return `
You are an expert AI disaster verification specialist. Analyze this image and description to determine authenticity and relevance.

DESCRIPTION PROVIDED: "${description}"

Please analyze the image and provide a JSON response with the following structure:
{
  "isAuthentic": boolean,
  "confidence": number (0-100),
  "matchScore": number (0-100),
  "analysis": "detailed explanation",
  "flags": ["array", "of", "issues"],
  "detectedElements": ["list", "of", "visible", "elements"],
  "disasterType": "flood|fire|landslide|earthquake|storm|other",
  "urgencyLevel": "low|medium|high",
  "recommendations": "action recommendations"
}

ANALYSIS CRITERIA:
1. AUTHENTICITY: Check for signs of manipulation, deepfakes, or generated content
2. RELEVANCE: Does the image match the description provided?
3. DISASTER INDICATORS: Look for genuine disaster-related elements
4. CONTEXT CLUES: Analyze lighting, shadows, perspective, people's reactions
5. METADATA CONCERNS: Note any suspicious visual artifacts

SCORING GUIDELINES:
- confidence: How certain you are about your assessment (0-100)
- matchScore: How well the image matches the description (0-100)
- isAuthentic: true if image appears real and relevant, false if suspicious

FLAGS TO CONSIDER:
- "potential_manipulation" - if image shows signs of editing
- "content_mismatch" - if image doesn't match description
- "low_quality" - if image quality is suspiciously poor
- "suspicious_elements" - if something looks fake or staged
- "metadata_concerns" - if visual metadata seems inconsistent

Be thorough but concise. Focus on disaster management context.
`;
  }

  /**
   * Parse Gemini's response and convert to VerificationResult
   */
  private parseGeminiResponse(
    analysisText: string, 
    options: AIVerificationOptions
  ): VerificationResult {
    try {
      // Extract JSON from the response (Gemini sometimes adds extra text)
      const jsonMatch = analysisText.match(/\{[\s\S]*\}/);
      
      if (!jsonMatch) {
        throw new Error('No JSON found in Gemini response');
      }

      const parsedResponse = JSON.parse(jsonMatch[0]);
      
      const { minConfidenceThreshold = 0.7 } = options;
      
      return {
        isVerifying: false,
        isAuthentic: parsedResponse.isAuthentic && (parsedResponse.confidence >= minConfidenceThreshold * 100),
        confidence: parsedResponse.confidence || 0,
        analysis: parsedResponse.analysis || 'Analysis completed',
        matchScore: parsedResponse.matchScore || 0,
        flags: parsedResponse.flags || []
      };

    } catch (error) {
      console.error('Failed to parse Gemini response:', error);
      console.log('Raw Gemini response:', analysisText);
      
      // Fallback parsing for non-JSON responses
      return this.parseNonJsonResponse(analysisText, options);
    }
  }

  /**
   * Fallback parser for when Gemini returns non-JSON text
   */
  private parseNonJsonResponse(
    analysisText: string, 
    options: AIVerificationOptions
  ): VerificationResult {
    const text = analysisText.toLowerCase();
    
    // Simple keyword-based analysis
    const authenticKeywords = ['authentic', 'genuine', 'real', 'legitimate'];
    const suspiciousKeywords = ['fake', 'manipulated', 'suspicious', 'artificial', 'generated'];
    
    const authenticScore = authenticKeywords.filter(word => text.includes(word)).length;
    const suspiciousScore = suspiciousKeywords.filter(word => text.includes(word)).length;
    
    const confidence = Math.min(90, Math.max(10, (authenticScore - suspiciousScore + 2) * 20));
    const isAuthentic = authenticScore > suspiciousScore && confidence >= (options.minConfidenceThreshold || 0.7) * 100;
    
    return {
      isVerifying: false,
      isAuthentic,
      confidence,
      analysis: `Gemini analysis: ${analysisText.substring(0, 200)}...`,
      matchScore: confidence,
      flags: isAuthentic ? [] : ['gemini_parsing_issue']
    };
  }

  /**
   * Fallback to mock analysis when Gemini API is unavailable
   */
  private async fallbackMockAnalysis(
    imageUrl: string, 
    description: string, 
    options: AIVerificationOptions
  ): Promise<VerificationResult> {
    console.log('Using fallback mock analysis...');
    
    // Simulate processing time
    await this.simulateProcessingTime();

    // Step 1: Extract image features (mock)
    const imageFeatures = await this.extractImageFeatures(imageUrl);
    
    // Step 2: Analyze description for disaster-related content
    const descriptionAnalysis = this.analyzeDescription(description);
    
    // Step 3: Cross-reference image content with description
    const contentMatch = this.calculateContentMatch(imageFeatures, descriptionAnalysis);
    
    // Step 4: Check for manipulation signs
    const manipulationCheck = await this.detectImageManipulation(imageUrl);
    
    // Step 5: Metadata verification
    const metadataCheck = options.checkMetadata ? await this.verifyMetadata(imageUrl) : { valid: true, score: 100 };
    
    // Step 6: Calculate final authenticity score
    const finalResult = this.calculateFinalScore({
      contentMatch,
      manipulationCheck,
      metadataCheck,
      descriptionAnalysis,
      strictMode: options.strictMode,
      minConfidenceThreshold: options.minConfidenceThreshold
    });

    return {
      ...finalResult,
      analysis: `ðŸ”„ Fallback Analysis: ${finalResult.analysis}`
    };
  }

  private async simulateProcessingTime(): Promise<void> {
    // Simulate realistic AI processing time (2-5 seconds)
    const delay = 2000 + Math.random() * 3000;
    await new Promise(resolve => setTimeout(resolve, delay));
  }

  private async extractImageFeatures(imageUrl: string) {
    // Mock image feature extraction
    // In real implementation, this would use computer vision APIs
    const disasterElements = [
      'water', 'flood', 'fire', 'smoke', 'debris', 'damage', 
      'emergency_vehicles', 'people', 'buildings', 'roads'
    ];

    const detectedElements = disasterElements
      .filter(() => Math.random() > 0.6)
      .slice(0, Math.floor(Math.random() * 4) + 1);

    return {
      detectedObjects: detectedElements,
      confidence: Math.random() * 0.3 + 0.7, // 70-100%
      imageQuality: Math.random() * 0.2 + 0.8, // 80-100%
      colorAnalysis: {
        dominantColors: ['blue', 'brown', 'gray'],
        brightness: Math.random()
      }
    };
  }

  private analyzeDescription(description: string) {
    const disasterKeywords = {
      flood: ['flood', 'water', 'inundation', 'overflow', 'submerged'],
      fire: ['fire', 'flame', 'smoke', 'burning', 'blaze'],
      landslide: ['landslide', 'mudslide', 'slope', 'debris', 'rocks'],
      earthquake: ['earthquake', 'crack', 'collapsed', 'damaged', 'shaking'],
      storm: ['storm', 'wind', 'cyclone', 'hurricane', 'typhoon']
    };

    const text = description.toLowerCase();
    let detectedCategory = 'other';
    let keywordMatches = 0;

    Object.entries(disasterKeywords).forEach(([category, keywords]) => {
      const matches = keywords.filter(keyword => text.includes(keyword)).length;
      if (matches > keywordMatches) {
        keywordMatches = matches;
        detectedCategory = category;
      }
    });

    return {
      category: detectedCategory,
      keywordMatches,
      urgencyLevel: this.assessUrgencyLevel(text),
      sentiment: this.analyzeSentiment(text)
    };
  }

  private calculateContentMatch(imageFeatures: any, descriptionAnalysis: any): number {
    // Mock content matching algorithm
    const baseScore = Math.random() * 0.3 + 0.5; // 50-80%
    
    // Bonus for keyword matches
    const keywordBonus = Math.min(descriptionAnalysis.keywordMatches * 0.1, 0.2);
    
    // Penalty for poor image quality
    const qualityPenalty = (1 - imageFeatures.imageQuality) * 0.1;
    
    return Math.max(0, Math.min(1, baseScore + keywordBonus - qualityPenalty));
  }

  private async detectImageManipulation(imageUrl: string) {
    // Mock deepfake/manipulation detection
    // In real implementation, use specialized AI models for forgery detection
    const manipulationScore = Math.random() * 0.3; // 0-30% manipulation likelihood
    
    return {
      isManipulated: manipulationScore > 0.2,
      confidence: 1 - manipulationScore,
      flags: manipulationScore > 0.2 ? ['potential_manipulation'] : []
    };
  }

  private async verifyMetadata(imageUrl: string) {
    // Mock metadata verification
    // In real implementation, check EXIF data, timestamps, GPS coordinates
    const metadataValid = Math.random() > 0.1; // 90% chance metadata is valid
    
    return {
      valid: metadataValid,
      score: metadataValid ? Math.random() * 20 + 80 : Math.random() * 40 + 20,
      flags: metadataValid ? [] : ['suspicious_metadata']
    };
  }

  private assessUrgencyLevel(text: string): 'low' | 'medium' | 'high' {
    const urgentWords = ['emergency', 'urgent', 'immediate', 'critical', 'danger'];
    const urgentCount = urgentWords.filter(word => text.includes(word)).length;
    
    if (urgentCount >= 2) return 'high';
    if (urgentCount >= 1) return 'medium';
    return 'low';
  }

  private analyzeSentiment(text: string): 'neutral' | 'distressed' | 'panic' {
    const distressWords = ['help', 'scared', 'trapped', 'emergency'];
    const panicWords = ['panic', 'terror', 'disaster', 'catastrophe'];
    
    if (panicWords.some(word => text.includes(word))) return 'panic';
    if (distressWords.some(word => text.includes(word))) return 'distressed';
    return 'neutral';
  }

  private calculateFinalScore(params: any): VerificationResult {
    const {
      contentMatch,
      manipulationCheck,
      metadataCheck,
      descriptionAnalysis,
      strictMode,
      minConfidenceThreshold
    } = params;

    const matchScore = Math.round(contentMatch * 100);
    const confidence = Math.round(
      (contentMatch * 0.4 + 
       manipulationCheck.confidence * 0.3 + 
       metadataCheck.score * 0.003) * 100
    );

    const isAuthentic = confidence >= (minConfidenceThreshold * 100) && 
                       !manipulationCheck.isManipulated &&
                       metadataCheck.valid;

    const flags = [
      ...manipulationCheck.flags,
      ...metadataCheck.flags,
      ...(confidence < 60 ? ['low_confidence'] : []),
      ...(matchScore < 70 ? ['content_mismatch'] : [])
    ];

    let analysis = this.generateAnalysis(isAuthentic, confidence, matchScore, descriptionAnalysis, flags);

    return {
      isVerifying: false,
      isAuthentic,
      confidence,
      analysis,
      matchScore,
      flags
    };
  }

  private generateAnalysis(
    isAuthentic: boolean, 
    confidence: number, 
    matchScore: number, 
    descriptionAnalysis: any,
    flags: string[]
  ): string {
    if (isAuthentic) {
      return `âœ… Image appears authentic with ${confidence}% confidence. Visual content aligns well with the reported ${descriptionAnalysis.category} incident. No significant manipulation detected.`;
    } else {
      const issues = [];
      if (confidence < 60) issues.push('low confidence score');
      if (matchScore < 70) issues.push('content mismatch with description');
      if (flags.includes('potential_manipulation')) issues.push('possible image manipulation');
      if (flags.includes('suspicious_metadata')) issues.push('metadata inconsistencies');
      
      return `âš ï¸ Image authenticity is questionable (${confidence}% confidence). Issues detected: ${issues.join(', ')}. Manual review recommended.`;
    }
  }
}

// Export singleton instance
export const aiVerificationService = ImageVerificationService.getInstance();

// Utility functions for common verification tasks
export const quickVerify = async (imageUrl: string, description: string): Promise<VerificationResult> => {
  return aiVerificationService.verifyImageAuthenticity(imageUrl, description);
};

export const strictVerify = async (imageUrl: string, description: string): Promise<VerificationResult> => {
  return aiVerificationService.verifyImageAuthenticity(imageUrl, description, {
    strictMode: true,
    minConfidenceThreshold: 0.8,
    checkMetadata: true,
    detectDeepfakes: true
  });
};